前言：
概率论的理解有些抽象，掌握概率论的方法，用实际样本去无限接近真实，熟练掌握并且使用一些最基本的概念是前提，比如，均值，方差
* # 排列 组合
计算各种公式的基础
排列
![image.png](http://upload-images.jianshu.io/upload_images/1652713-36e8b57773e40cd2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


组合
![image.png](http://upload-images.jianshu.io/upload_images/1652713-63ed1967b0c454b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

* # 古典概率
事件A
构成事件A发生的**基本时间**有a个
不构成事件A发生的基本事件有b个
![image.png](http://upload-images.jianshu.io/upload_images/1652713-67765cec3fd00821.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


* # 联合概率
两个事件共同发生记为P（AB）

* # 条件概率
事件A在另外一个事件B已经发生的条件下的发生概率叫做 条件概率
![image.png](http://upload-images.jianshu.io/upload_images/1652713-773ca1c020824072.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
推论：如果n个事件同时发生
![image.png](http://upload-images.jianshu.io/upload_images/1652713-2abbea23e1222f1a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640)

* # 全概率公式
样本空间Ω有一组事件A1、A2...An
如图：
![image.png](http://upload-images.jianshu.io/upload_images/1652713-4e8f7123c5166563.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
那么对于任意事件B，全概率公式为: 
![image.png](http://upload-images.jianshu.io/upload_images/1652713-ea6ca0dff7813dbb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
又叫结果概率公式（B事件一般为结果事件）

* # 贝叶斯公式
可由条件概率公式证明
![image.png](http://upload-images.jianshu.io/upload_images/1652713-02878630c4f7e09c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
假如A1、A2...An是样本空间Ω的一个划分，如果 对任意事件B而言，有P(B)>0，那么：
![image.png](http://upload-images.jianshu.io/upload_images/1652713-9e417d37ec758d8b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/620)
又叫原因概率公式，事件B已经发生的情况下查找原因

* # 独立事件
A,B发生无关
![image.png](http://upload-images.jianshu.io/upload_images/1652713-236527e8b2d7690c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

* # 随机变量
把前面说的事件A,B具体化，用变量和函数来表达前面说的该事件在样本空间的概率
例： 掷一颗骰子，令 X：出现的点数． 
例：上午 8:00～9:00 在某路口观察，令： Y：该时间间隔内通过的汽车数． 则 Y 就是一个随机变量
* # 离散型随机变量
![image.png](http://upload-images.jianshu.io/upload_images/1652713-0c4dfa8e571a58ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/620)
* 1) Bernoulli分布
![image.png](http://upload-images.jianshu.io/upload_images/1652713-a3641850134b1e86.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
记做：
![image.png](http://upload-images.jianshu.io/upload_images/1652713-fd3d3d188bed3c23.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
注意参数1为一次实验，p为发生事件的概率
* 2）二 项 分 布
进行n次试验发生k次的概率
![](http://upload-images.jianshu.io/upload_images/1652713-a1c7739ef99c2c9a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
记为
![image.png](http://upload-images.jianshu.io/upload_images/1652713-dbb1e1b2efda447a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
* 3）Poisson 分布 
当n取无穷大二向分布的近似
![image.png](http://upload-images.jianshu.io/upload_images/1652713-3fb50994baca45b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
其中参数取值为：
![image.png](http://upload-images.jianshu.io/upload_images/1652713-5ff52221d18e1055.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



* 4）几 何 分 布
在Bernoulli试验中，试验进行到A 首次出现为止
![image.png](http://upload-images.jianshu.io/upload_images/1652713-397c836352afe322.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

* 5）超 几 何 分 布
一批产品有 N 件，其中有 M 件次品，其余 N-M 件为正品．现从中取出 n 件． 令 X：取出 n 件产品中的次品数． 则 X 的分 布律为
![image.png](http://upload-images.jianshu.io/upload_images/1652713-2307a8f768fe8332.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640)

* # 连续型随机变量
分布函数F（x）
概率密度函数分f（x）
* 1） 均 匀 分 布 
![image.png](http://upload-images.jianshu.io/upload_images/1652713-981dbf6df28e84d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
记为
![image.png](http://upload-images.jianshu.io/upload_images/1652713-8976fa2057faee66.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


* 2) 指 数 分 布

* 3)正 态 分 布
![image.png](http://upload-images.jianshu.io/upload_images/1652713-1cfdb7263d25fb37.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640)
一般正态函数的计算，先转化为标准正态函数


*  #期望和方差
学完最好，证明一下前面各个分布的期望和方差
* 期望
也就是均值，是概率加权下的“平均值”，是每次可能 结果的概率乘以其结果的总和，反映的实随机变量平均取值大小。 常用符号 表示 
![image.png](http://upload-images.jianshu.io/upload_images/1652713-3c5b9a2427c4cdb7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
* 方差
方差是衡量数据 源数据和期望均值相差的度量值。 
![image.png](http://upload-images.jianshu.io/upload_images/1652713-d9fa0977f85d77b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
常见分布的期望和方差如下：
![image.png](http://upload-images.jianshu.io/upload_images/1652713-819663ffb053169b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
* 协方差
协方差常用于衡量两个变量的总体误差
* 相关系数
两个变量相关程度
* 中心矩、原点矩
X的数学期望E(X)是X的一阶原点矩。
 X的方差D(X)是X的二阶中心矩。 
X和Y的协方差Cov(X,Y)是X和Y的二阶混合中心矩
* 峰度
反应峰部的尖度
* 偏度
右偏还是左偏
* #三个基本定理

*  切比雪夫不等式 /切比雪夫定理
设随机变量X的期望为μ，方差为σ2，对于任意的正数ε，有：
![image.png](http://upload-images.jianshu.io/upload_images/1652713-ff68c3044e0d27d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
切比雪夫不等式的含义是：DX(方差)越小，时间{|X-μ|<ε}发生的概 率就越大，即：X取的值基本上集中在期望μ附近 
*  大数定律
随着样本容量n的增加，样本平均数将接近于总体 平均数(期望μ)
为使用频率来估计概率提供了理论支持
* 中心极限定理
当样本n充分大时，样本均值的抽样分布近似 服从均值为μ/n、方差为σ2/n 的正态分布。 
* # 参数估计
参数估计是概率论的应用，就是我们怎么通过实验获得的值来估计概率函数的参数
* 点估计
分布函数的形式已知，参数未知
对未知参数进行定值估计，**极大似然和矩估计是点估计的一种算法**
* 矩估计
和极大似然估计的区别是，利用大数定律中的样本均值和总体平均值一样，求出参数
![image.png](http://upload-images.jianshu.io/upload_images/1652713-a708042f5b117fb3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
* 极大似然估计
注意分布函数已知，写出似然函数，求导，求出参数值
1）离散型
![image.png](http://upload-images.jianshu.io/upload_images/1652713-bcfe62de731b52d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640)

2）连续型
![image.png](http://upload-images.jianshu.io/upload_images/1652713-a4eeebbb337fb45a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640)
由于f（x）>0，f(x)取对数之后的单调性不变，所以可转化为：
![image.png](http://upload-images.jianshu.io/upload_images/1652713-9807ae189d2f8167.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640)







*你可能感冒的文章：
[我的机器学习pandas篇](http://www.jianshu.com/p/82245c5bed99)
[我的机器学习matplotlib篇](http://www.jianshu.com/p/f2ebf312e323)
[我的机器学习numpy篇](https://www.jianshu.com/p/3a757f14a713)*

